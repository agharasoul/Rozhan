"use client";

import { useState, useRef, useCallback } from "react";
import { useAuth } from "../contexts/AuthContext";
import { Mic, Square, Loader2, Volume2 } from "lucide-react";

// Ø¢Ø¯Ø±Ø³ API - Ø¯Ø§ÛŒÙ†Ø§Ù…ÛŒÚ© Ø¨Ø± Ø§Ø³Ø§Ø³ hostname Ùˆ Ù¾Ø±ÙˆØªÚ©Ù„
const getApiBase = () => {
  if (typeof window === 'undefined') return "https://localhost:9999";
  const hostname = window.location.hostname;
  const isSecure = window.location.protocol === 'https:';
  return `${isSecure ? 'https' : 'http'}://${hostname}:9999`;
};

interface SimpleVoiceChatProps {
  onMessage?: (text: string, role: "user" | "assistant") => void;
  sessionId?: string;
}

type VoiceState = "idle" | "recording" | "processing" | "speaking";

export default function SimpleVoiceChat({ onMessage, sessionId }: SimpleVoiceChatProps) {
  const [state, setState] = useState<VoiceState>("idle");
  const [transcript, setTranscript] = useState("");
  const [response, setResponse] = useState("");
  
  const { token } = useAuth();

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const recordingTimeoutRef = useRef<number | null>(null);

  // Ø´Ø±ÙˆØ¹ Ø¶Ø¨Ø· ØµØ¯Ø§
  const startRecording = useCallback(async () => {
    try {
      // Ú†Ú© Ú©Ø±Ø¯Ù† Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…Ø±ÙˆØ±Ú¯Ø±
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        alert("Ù…Ø±ÙˆØ±Ú¯Ø± Ø´Ù…Ø§ Ø§Ø² Ø¶Ø¨Ø· ØµØ¯Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯");
        return;
      }
      
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
        } 
      });
      
      // Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† MIME type Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø´Ø¯Ù‡
      let mimeType = 'audio/webm';
      if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
        mimeType = 'audio/webm;codecs=opus';
      } else if (MediaRecorder.isTypeSupported('audio/webm')) {
        mimeType = 'audio/webm';
      } else if (MediaRecorder.isTypeSupported('audio/mp4')) {
        mimeType = 'audio/mp4';
      } else if (MediaRecorder.isTypeSupported('audio/ogg')) {
        mimeType = 'audio/ogg';
      }
      
      const mediaRecorder = new MediaRecorder(stream, { mimeType });
      
      audioChunksRef.current = [];
      
      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          audioChunksRef.current.push(e.data);
        }
      };
      
      mediaRecorder.onstop = async () => {
        // ØªÙˆÙ‚Ù stream
        stream.getTracks().forEach(track => track.stop());
        
        // Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµØ¯Ø§
        await processAudio();
      };
      
      mediaRecorderRef.current = mediaRecorder;
      mediaRecorder.start(100); // Ù‡Ø± 100ms ÛŒÙ‡ chunk

      // Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø·ÙˆÙ„ Ø¶Ø¨Ø· Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ ØªØ£Ø®ÛŒØ± (Ù…Ø«Ù„Ø§Ù‹ Ø­Ø¯Ø§Ú©Ø«Ø± Û¸ Ø«Ø§Ù†ÛŒÙ‡)
      if (recordingTimeoutRef.current) {
        clearTimeout(recordingTimeoutRef.current);
      }
      recordingTimeoutRef.current = window.setTimeout(() => {
        if (mediaRecorderRef.current && mediaRecorderRef.current.state === "recording") {
          mediaRecorderRef.current.stop();
          setState("processing");
        }
      }, 8000);
      setState("recording");
      setTranscript("");
      setResponse("");
      
    } catch (error: any) {
      console.error("Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙ†:", error);
      if (error.name === 'NotAllowedError') {
        alert("Ù„Ø·ÙØ§Ù‹ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙ† Ø±Ø§ Ø¯Ø± ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø±ÙˆØ±Ú¯Ø± ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯");
      } else if (error.name === 'NotFoundError') {
        alert("Ù…ÛŒÚ©Ø±ÙˆÙÙ†ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯");
      } else {
        alert("Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙ†: " + error.message);
      }
      setState("idle");
    }
  }, []);

  // ØªÙˆÙ‚Ù Ø¶Ø¨Ø·
  const stopRecording = useCallback(() => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === "recording") {
      mediaRecorderRef.current.stop();
      setState("processing");
    }
    if (recordingTimeoutRef.current) {
      clearTimeout(recordingTimeoutRef.current);
      recordingTimeoutRef.current = null;
    }
  }, []);

  // ØªØ¨Ø¯ÛŒÙ„ Blob Ø¨Ù‡ base64
  const blobToBase64 = (blob: Blob): Promise<string> => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onloadend = () => {
        const base64 = (reader.result as string).split(',')[1];
        resolve(base64);
      };
      reader.onerror = reject;
      reader.readAsDataURL(blob);
    });
  };

  // Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµØ¯Ø§: transcribe â†’ chat â†’ tts
  const processAudio = useCallback(async () => {
    const API_BASE = getApiBase();
    
    try {
      console.log("ðŸŽ¤ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµØ¯Ø§...");
      console.log("ØªØ¹Ø¯Ø§Ø¯ chunks:", audioChunksRef.current.length);
      
      // 1. ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Blob
      const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
      console.log("Ø³Ø§ÛŒØ² Blob:", audioBlob.size, "bytes");
      
      if (audioBlob.size < 1000) {
        console.warn("ØµØ¯Ø§ Ø®ÛŒÙ„ÛŒ Ú©ÙˆØªØ§Ù‡ Ø¨ÙˆØ¯");
        setState("idle");
        return;
      }
      
      // 2. ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ base64
      const audioBase64 = await blobToBase64(audioBlob);
      console.log("Ø³Ø§ÛŒØ² base64:", audioBase64.length);
      
      // 3. Transcribe - ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ†
      console.log("ðŸ“¤ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ /transcribe...");
      const transcribeRes = await fetch(`${API_BASE}/transcribe`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          audio: audioBase64,
          mime_type: 'audio/webm',
        }),
      });
      
      console.log("ðŸ“¥ Ù¾Ø§Ø³Ø® transcribe:", transcribeRes.status);
      
      if (!transcribeRes.ok) {
        const errText = await transcribeRes.text();
        console.error("Ø®Ø·Ø§ÛŒ transcribe:", errText);
        throw new Error("Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ†");
      }
      
      const transcribeData = await transcribeRes.json();
      const userText = transcribeData.text || "";
      console.log("âœ… Ù…ØªÙ† ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡:", userText);
      
      if (!userText.trim()) {
        console.warn("Ù…ØªÙ†ÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ù†Ø´Ø¯");
        setState("idle");
        return;
      }
      
      setTranscript(userText);
      onMessage?.(userText, "user");
      
      // 4. Chat - Ú¯Ø±ÙØªÙ† Ù¾Ø§Ø³Ø® Ø§Ø² Gemini
      console.log("ðŸ“¤ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ /chat...");
      const chatBody: any = { message: userText };
      // ÙÙ‚Ø· Ø§Ú¯Ù‡ sessionId Ø¹Ø¯Ø¯ Ø¨Ø§Ø´Ù‡ Ø¨ÙØ±Ø³Øª
      if (sessionId && typeof sessionId === 'number') {
        chatBody.session_id = sessionId;
      }

      const chatHeaders: Record<string, string> = {
        'Content-Type': 'application/json',
      };
      // Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ù„Ø§Ú¯ÛŒÙ† Ø¨Ø§Ø´Ø¯ØŒ ØªÙˆÚ©Ù† Ø±Ø§ Ø¨Ø±Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø¨ÙØ±Ø³Øª
      if (token) {
        chatHeaders['Authorization'] = `Bearer ${token}`;
      }

      const chatRes = await fetch(`${API_BASE}/chat`, {
        method: 'POST',
        headers: chatHeaders,
        body: JSON.stringify(chatBody),
      });
      
      console.log("ðŸ“¥ Ù¾Ø§Ø³Ø® chat:", chatRes.status);
      
      if (!chatRes.ok) {
        const errText = await chatRes.text();
        console.error("Ø®Ø·Ø§ÛŒ chat:", errText);
        throw new Error("Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø®");
      }
      
      const chatData = await chatRes.json();
      const assistantText = chatData.response || "";
      const assistantEmotion: string = chatData.emotion || "neutral";
      console.log("âœ… Ù¾Ø§Ø³Ø® Ø±ÙˆÚ˜Ø§Ù†:", assistantText.substring(0, 100));
      console.log("ðŸ˜ƒ Ø§Ø­Ø³Ø§Ø³ ØªØ´Ø®ÛŒØµâ€ŒØ¯Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡:", assistantEmotion);
      
      setResponse(assistantText);
      onMessage?.(assistantText, "assistant");
      
      // 5. TTS - ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ ØµØ¯Ø§
      console.log("ðŸ“¤ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ /tts...");
      setState("speaking");

      // Ø§Ù†ØªØ®Ø§Ø¨ ØµØ¯Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø­Ø³Ø§Ø³ Ú©Ø§Ø±Ø¨Ø±
      let ttsVoice = "fa-IR-FaridNeural"; // Ù¾ÛŒØ´â€ŒÙØ±Ø¶: ÙØ±ÛŒØ¯ (Ø´Ø§Ø¯/Ø®Ù†Ø«ÛŒ)
      if (assistantEmotion === "sad" || assistantEmotion === "disappointed") {
        ttsVoice = "fa-IR-DilaraNeural"; // ØºÙ…Ú¯ÛŒÙ†/Ø¯Ù„Ø®ÙˆØ± â†’ Ø¯ÛŒÙ„Ø§Ø±Ø§
      } else if (assistantEmotion === "angry") {
        // Ø¹ØµØ¨Ø§Ù†ÛŒ â†’ ØµØ¯Ø§ÛŒ Ø®Ù†Ø«ÛŒ Ù…Ø±Ø¯Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ø¢Ø±Ø§Ù… Ú©Ø±Ø¯Ù† ÙØ¶Ø§
        ttsVoice = "fa-IR-FaridNeural";
      } else if (assistantEmotion === "hurry") {
        // Ø¹Ø¬Ù„Ù‡ â†’ Ù‡Ù…Ø§Ù† ÙØ±ÛŒØ¯ØŒ ÙˆÙ„ÛŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒÙ… Ø¨Ø¹Ø¯Ø§Ù‹ Ù…ØªÙ† Ø±Ø§ Ú©ÙˆØªØ§Ù‡â€ŒØªØ± Ú©Ù†ÛŒÙ…
        ttsVoice = "fa-IR-FaridNeural";
      }

      const ttsRes = await fetch(`${API_BASE}/tts`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          text: assistantText,
          voice: ttsVoice,
        }),
      });
      
      console.log("ðŸ“¥ Ù¾Ø§Ø³Ø® tts:", ttsRes.status);
      
      if (!ttsRes.ok) {
        const errText = await ttsRes.text();
        console.error("Ø®Ø·Ø§ÛŒ tts:", errText);
        throw new Error("Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ ØµØ¯Ø§");
      }
      
      const ttsData = await ttsRes.json();
      
      if (ttsData.audio) {
        console.log("ðŸ”Š Ù¾Ø®Ø´ ØµØ¯Ø§...");
        console.log("Ø³Ø§ÛŒØ² audio:", ttsData.audio.length);
        console.log("Ø´Ø±ÙˆØ¹ audio:", ttsData.audio.substring(0, 50));
        
        // Ø§Ú¯Ù‡ data URI Ú©Ø§Ù…Ù„ Ø¨ÙˆØ¯ Ù…Ø³ØªÙ‚ÛŒÙ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ØŒ ÙˆÚ¯Ø±Ù†Ù‡ Ø¨Ø³Ø§Ø²
        const audioSrc = ttsData.audio.startsWith('data:') 
          ? ttsData.audio 
          : `data:audio/mpeg;base64,${ttsData.audio}`;
        
        console.log("audioSrc Ø´Ø±ÙˆØ¹:", audioSrc.substring(0, 50));
        
        const audio = new Audio(audioSrc);
        audioRef.current = audio;
        
        audio.oncanplaythrough = () => {
          console.log("âœ… ØµØ¯Ø§ Ø¢Ù…Ø§Ø¯Ù‡ Ù¾Ø®Ø´");
        };
        
        audio.onended = () => {
          console.log("âœ… Ù¾Ø®Ø´ ØªÙ…Ø§Ù… Ø´Ø¯");
          setState("idle");
        };
        
        audio.onerror = (e) => {
          console.error("âŒ Ø®Ø·Ø§ÛŒ Ù¾Ø®Ø´ ØµØ¯Ø§:", e);
          console.error("audio error code:", audio.error?.code);
          console.error("audio error message:", audio.error?.message);
          setState("idle");
        };
        
        try {
          await audio.play();
          console.log("â–¶ï¸ Ù¾Ø®Ø´ Ø´Ø±ÙˆØ¹ Ø´Ø¯");
        } catch (playError) {
          console.error("âŒ Ø®Ø·Ø§ÛŒ play():", playError);
          setState("idle");
        }
      } else {
        console.warn("ØµØ¯Ø§ÛŒÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯ - ttsData:", ttsData);
        setState("idle");
      }
      
    } catch (error) {
      console.error("âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´:", error);
      setState("idle");
    }
  }, [sessionId, onMessage, token]);

  // Toggle Ø¶Ø¨Ø·
  const toggleRecording = useCallback(() => {
    if (state === "idle") {
      startRecording();
    } else if (state === "recording") {
      stopRecording();
    } else if (state === "speaking") {
      // ØªÙˆÙ‚Ù Ù¾Ø®Ø´
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current = null;
      }
      setState("idle");
    }
  }, [state, startRecording, stopRecording]);

  // Ø±Ù†Ú¯ Ùˆ Ø¢ÛŒÚ©ÙˆÙ† Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ¶Ø¹ÛŒØª
  const getButtonStyle = () => {
    switch (state) {
      case "recording":
        return "bg-red-500 hover:bg-red-600 animate-pulse";
      case "processing":
        return "bg-yellow-500 cursor-wait";
      case "speaking":
        return "bg-emerald-500 hover:bg-emerald-600";
      default:
        return "bg-violet-500 hover:bg-violet-600";
    }
  };

  const getIcon = () => {
    switch (state) {
      case "recording":
        return <Square className="w-5 h-5 fill-current" />;
      case "processing":
        return <Loader2 className="w-5 h-5 animate-spin" />;
      case "speaking":
        return <Volume2 className="w-5 h-5" />;
      default:
        return <Mic className="w-5 h-5" />;
    }
  };

  const getLabel = () => {
    switch (state) {
      case "recording":
        return "Ø¯Ø± Ø­Ø§Ù„ Ø¶Ø¨Ø·...";
      case "processing":
        return "Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...";
      case "speaking":
        return "Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø®Ø´...";
      default:
        return "Ú†Øª ØµÙˆØªÛŒ";
    }
  };

  return (
    <div className="relative">
      {/* Ø¯Ú©Ù…Ù‡ Ø§ØµÙ„ÛŒ */}
      <button
        onClick={toggleRecording}
        disabled={state === "processing"}
        className={`
          flex items-center gap-2 px-4 py-2.5 rounded-full font-medium
          text-white shadow-lg transition-all duration-300
          ${getButtonStyle()}
        `}
      >
        {getIcon()}
        <span className="text-sm">{getLabel()}</span>
      </button>

      {/* Ù†Ù…Ø§ÛŒØ´ Ù…ØªÙ† (Ø§Ø®ØªÛŒØ§Ø±ÛŒ) */}
      {false && (transcript || response) && (
        <div 
          className="absolute top-full mt-2 right-0 w-72 p-3 bg-zinc-800 rounded-xl shadow-xl border border-zinc-700 text-sm text-right z-50"
          dir="rtl"
        >
          {transcript && (
            <div className="mb-2">
              <span className="text-xs text-zinc-400">Ø´Ù…Ø§:</span>
              <p className="text-zinc-300 line-clamp-2">{transcript}</p>
            </div>
          )}
          {response && (
            <div>
              <span className="text-xs text-emerald-400">Ø±ÙˆÚ˜Ø§Ù†:</span>
              <p className="text-zinc-200 line-clamp-3">{response}</p>
            </div>
          )}
        </div>
      )}
    </div>
  );
}
