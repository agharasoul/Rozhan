"""
ğŸ¤ğŸ”Š Ú†Øª ØµÙˆØªÛŒ Ø³Ø±ÛŒØ¹ Ø¨Ø§ GapGPT
STT (Whisper) â†’ Chat (Gemini Lite) â†’ TTS (OpenAI)
Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª
"""

import asyncio
import base64
import json
import httpx
from typing import Optional, AsyncGenerator
from config import GAPGPT_API_KEY, GAPGPT_BASE_URL

# Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒØ¹
STT_MODEL = "whisper-1"
CHAT_MODEL = "gemini-2.5-flash-lite"  # Ø³Ø±ÛŒØ¹â€ŒØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ú†Øª
TTS_MODEL = "tts-1"  # Ø³Ø±ÛŒØ¹â€ŒØªØ±ÛŒÙ† TTS
TTS_VOICE = "nova"  # ØµØ¯Ø§ÛŒ Ø²Ù†ØŒ Ø·Ø¨ÛŒØ¹ÛŒ

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª TTS Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø­Ø³Ø§Ø³
EMOTION_TTS_CONFIG = {
    "happy": {"rate": "+10%", "pitch": "+5Hz", "fa": "Ø®ÙˆØ´Ø­Ø§Ù„", "tone": "Ø´Ø§Ø¯ Ùˆ Ù¾Ø±Ø§Ù†Ø±Ú˜ÛŒ"},
    "sad": {"rate": "-15%", "pitch": "-5Hz", "fa": "ØºÙ…Ú¯ÛŒÙ†", "tone": "Ù‡Ù…Ø¯Ø±Ø¯Ø§Ù†Ù‡ Ùˆ Ø¢Ø±Ø§Ù…"},
    "angry": {"rate": "-10%", "pitch": "-3Hz", "fa": "Ø¹ØµØ¨Ø§Ù†ÛŒ", "tone": "Ø¢Ø±Ø§Ù…Ø´â€ŒØ¨Ø®Ø´ Ùˆ ØµØ¨ÙˆØ±Ø§Ù†Ù‡"},
    "anxious": {"rate": "-5%", "pitch": "+0Hz", "fa": "Ù…Ø¶Ø·Ø±Ø¨", "tone": "Ø§Ø·Ù…ÛŒÙ†Ø§Ù†â€ŒØ¨Ø®Ø´"},
    "tired": {"rate": "-20%", "pitch": "-5Hz", "fa": "Ø®Ø³ØªÙ‡", "tone": "Ù…Ù„Ø§ÛŒÙ… Ùˆ Ú©ÙˆØªØ§Ù‡"},
    "excited": {"rate": "+15%", "pitch": "+8Hz", "fa": "Ù‡ÛŒØ¬Ø§Ù†â€ŒØ²Ø¯Ù‡", "tone": "Ù¾Ø±Ø§Ù†Ø±Ú˜ÛŒ"},
    "hurry": {"rate": "+20%", "pitch": "+0Hz", "fa": "Ø¹Ø¬Ù„Ù‡", "tone": "Ù…Ø®ØªØµØ± Ùˆ Ø³Ø±ÛŒØ¹"},
    "neutral": {"rate": "+0%", "pitch": "+0Hz", "fa": "Ø®Ù†Ø«ÛŒ", "tone": "Ø¹Ø§Ø¯ÛŒ"},
}

# System Prompt Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³
SYSTEM_PROMPT = """ØªÙˆ Ø±ÙˆÚ˜Ø§Ù† Ù‡Ø³ØªÛŒØŒ Ø¯Ø³ØªÛŒØ§Ø± ØµÙˆØªÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø±Ø³ØªÙˆØ±Ø§Ù†.

Ù‚ÙˆØ§Ù†ÛŒÙ† Ù…Ù‡Ù…:
1. ÙØ§Ø±Ø³ÛŒ Ù…Ø­Ø§ÙˆØ±Ù‡â€ŒØ§ÛŒ Ùˆ ØµÙ…ÛŒÙ…ÛŒ ØµØ­Ø¨Øª Ú©Ù†
2. Ø¬ÙˆØ§Ø¨â€ŒÙ‡Ø§Øª Ú©ÙˆØªØ§Ù‡ Ùˆ Ù…ÙÛŒØ¯ Ø¨Ø§Ø´Ù† (Ø¨Ø±Ø§ÛŒ Ù…Ú©Ø§Ù„Ù…Ù‡ ØµÙˆØªÛŒ)
3. Ø§Ø² Ù„Ø­Ù† ØµØ¯Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø§Ø­Ø³Ø§Ø³Ø´ Ø±Ùˆ Ø¯Ø±Ú© Ú©Ù† Ùˆ Ù…ØªÙ†Ø§Ø³Ø¨ Ø¬ÙˆØ§Ø¨ Ø¨Ø¯Ù‡:
   - Ø§Ú¯Ù‡ Ø¹ØµØ¨Ø§Ù†ÛŒ Ø¨ÙˆØ¯: Ø¢Ø±ÙˆÙ… Ùˆ ØµØ¨ÙˆØ±Ø§Ù†Ù‡ Ø¬ÙˆØ§Ø¨ Ø¨Ø¯Ù‡
   - Ø§Ú¯Ù‡ Ø®Ø³ØªÙ‡ Ø¨ÙˆØ¯: Ú©ÙˆØªØ§Ù‡ Ùˆ Ø³Ø±ÛŒØ¹ Ø¬ÙˆØ§Ø¨ Ø¨Ø¯Ù‡
   - Ø§Ú¯Ù‡ Ø®ÙˆØ´Ø­Ø§Ù„ Ø¨ÙˆØ¯: Ù¾Ø±Ø§Ù†Ø±Ú˜ÛŒ Ø¬ÙˆØ§Ø¨ Ø¨Ø¯Ù‡
   - Ø§Ú¯Ù‡ Ø¹Ø¬Ù„Ù‡ Ø¯Ø§Ø´Øª: Ù…Ø³ØªÙ‚ÛŒÙ… Ùˆ Ø¨Ø¯ÙˆÙ† Ø­Ø§Ø´ÛŒÙ‡ Ø¬ÙˆØ§Ø¨ Ø¨Ø¯Ù‡
4. Ø§ÙˆÙ„ Ø§Ø­Ø³Ø§Ø³ Ú©Ø§Ø±Ø¨Ø± Ø±Ùˆ Ø¯Ø± ÛŒÚ© Ú©Ù„Ù…Ù‡ Ø¨Ú¯ÙˆØŒ Ø¨Ø¹Ø¯ Ø¬ÙˆØ§Ø¨ Ø§ØµÙ„ÛŒ Ø±Ùˆ Ø¨Ø¯Ù‡

ÙˆØ¸Ø§ÛŒÙØª:
- Ú©Ù…Ú© Ø¨Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ ØºØ°Ø§
- Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ù„ÛŒÙ‚Ù‡
- Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù…Ù†Ùˆ
"""


class VoiceChatSession:
    """Ú†Øª ØµÙˆØªÛŒ Ø³Ø±ÛŒØ¹: STT â†’ Chat â†’ TTS"""
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or GAPGPT_API_KEY
        self.client = httpx.AsyncClient(timeout=30.0, verify=False)
        self.is_connected = False
        self.detected_emotion = "neutral"
        self.chat_history = []
        
    async def connect(self):
        """Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ session"""
        self.is_connected = True
        self.chat_history = []
        print("âœ… Voice chat session ready (Fast Mode)")
        return True
    
    async def transcribe(self, audio_data: bytes, mime_type: str = "audio/webm") -> str:
        """STT Ø¨Ø§ Whisper - Ø³Ø±ÛŒØ¹"""
        try:
            import tempfile, os
            ext = "webm" if "webm" in mime_type else "mp3"
            
            with tempfile.NamedTemporaryFile(suffix=f".{ext}", delete=False) as tmp:
                tmp.write(audio_data)
                tmp_path = tmp.name
            
            try:
                url = f"{GAPGPT_BASE_URL}v1/audio/transcriptions"
                with open(tmp_path, "rb") as f:
                    files = {"file": (f"audio.{ext}", f, mime_type)}
                    data = {"model": STT_MODEL, "language": "fa"}
                    headers = {"Authorization": f"Bearer {self.api_key}"}
                    
                    response = await self.client.post(url, files=files, data=data, headers=headers)
                    
                    if response.status_code == 200:
                        return response.json().get("text", "")
                    print(f"STT error: {response.status_code}")
                    return ""
            finally:
                os.unlink(tmp_path)
                
        except Exception as e:
            print(f"Transcribe error: {e}")
            return ""
    
    async def chat(self, text: str) -> str:
        """Chat Ø¨Ø§ Gemini Lite - Ø³Ø±ÛŒØ¹"""
        try:
            url = f"{GAPGPT_BASE_URL}v1beta/models/{CHAT_MODEL}:generateContent"
            
            self.chat_history.append({"role": "user", "parts": [{"text": text}]})
            
            # ÙÙ‚Ø· Ø¢Ø®Ø±ÛŒÙ† 6 Ù¾ÛŒØ§Ù… Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª
            recent_history = self.chat_history[-6:]
            
            payload = {
                "contents": recent_history,
                "systemInstruction": {"parts": [{"text": SYSTEM_PROMPT}]},
                "generationConfig": {
                    "temperature": 0.7,
                    "maxOutputTokens": 200  # Ù¾Ø§Ø³Ø® Ú©ÙˆØªØ§Ù‡ = Ø³Ø±ÛŒØ¹â€ŒØªØ±
                }
            }
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            response = await self.client.post(url, json=payload, headers=headers)
            
            if response.status_code == 200:
                result = response.json()
                if "candidates" in result and result["candidates"]:
                    reply = result["candidates"][0]["content"]["parts"][0]["text"]
                    
                    # ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³
                    for emotion in EMOTION_TTS_CONFIG.keys():
                        if EMOTION_TTS_CONFIG[emotion]["fa"] in reply[:50]:
                            self.detected_emotion = emotion
                            break
                    
                    self.chat_history.append({"role": "model", "parts": [{"text": reply}]})
                    return reply
            
            print(f"Chat error: {response.status_code} - {response.text[:200]}")
            return "Ù…ØªØ£Ø³ÙÙ…ØŒ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø§ÙˆÙ…Ø¯."
            
        except Exception as e:
            print(f"Chat error: {e}")
            return "Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø·"
    
    async def text_to_speech(self, text: str) -> bytes:
        """TTS Ø¨Ø§ OpenAI - Ø³Ø±ÛŒØ¹â€ŒØªØ±ÛŒÙ†"""
        try:
            url = f"{GAPGPT_BASE_URL}v1/audio/speech"
            
            payload = {
                "model": TTS_MODEL,
                "input": text,
                "voice": TTS_VOICE,
                "speed": 1.1  # Ú©Ù…ÛŒ Ø³Ø±ÛŒØ¹â€ŒØªØ±
            }
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            response = await self.client.post(url, json=payload, headers=headers)
            
            if response.status_code == 200:
                return response.content
            
            print(f"TTS error: {response.status_code}")
            return b""
            
        except Exception as e:
            print(f"TTS error: {e}")
            return b""
    
    async def process_audio(self, audio_data: bytes, mime_type: str = "audio/webm") -> AsyncGenerator:
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„: ØµØ¯Ø§ â†’ Ù…ØªÙ† â†’ Ù¾Ø§Ø³Ø® â†’ ØµØ¯Ø§"""
        if not self.is_connected:
            yield {"type": "error", "message": "Not connected"}
            return
        
        try:
            # 1. STT
            user_text = await self.transcribe(audio_data, mime_type)
            if not user_text:
                yield {"type": "error", "message": "Ù†ØªÙˆÙ†Ø³ØªÙ… ØµØ¯Ø§ØªÙˆ Ø¨ÙÙ‡Ù…Ù…"}
                return
            
            yield {"type": "user_text", "data": user_text}
            
            # 2. Chat
            reply = await self.chat(user_text)
            yield {
                "type": "text",
                "data": reply,
                "emotion": self.detected_emotion
            }
            
            # 3. TTS
            audio = await self.text_to_speech(reply)
            if audio:
                yield {
                    "type": "audio",
                    "data": base64.b64encode(audio).decode(),
                    "mime_type": "audio/mp3",
                    "emotion": self.detected_emotion
                }
            
            yield {"type": "turn_complete", "emotion": self.detected_emotion}
            
        except Exception as e:
            print(f"Process audio error: {e}")
            yield {"type": "error", "message": str(e)}
    
    async def close(self):
        """Ø¨Ø³ØªÙ† session"""
        await self.client.aclose()
        self.is_connected = False
        self.chat_history = []
        print("ğŸ”´ Session closed")


# Ù…Ø¯ÛŒØ±ÛŒØª sessions
active_sessions = {}

async def create_session(session_id: str, api_key: str = None) -> VoiceChatSession:
    """Ø³Ø§Ø®Øª ÛŒÚ© session Ø¬Ø¯ÛŒØ¯"""
    session = VoiceChatSession(api_key)
    if await session.connect():
        active_sessions[session_id] = session
        return session
    return None

async def get_session(session_id: str) -> Optional[VoiceChatSession]:
    """Ú¯Ø±ÙØªÙ† session Ù…ÙˆØ¬ÙˆØ¯"""
    return active_sessions.get(session_id)

async def close_session(session_id: str):
    """Ø¨Ø³ØªÙ† Ùˆ Ø­Ø°Ù session"""
    if session_id in active_sessions:
        await active_sessions[session_id].close()
        del active_sessions[session_id]


# ØªØ³Øª
if __name__ == "__main__":
    async def test():
        session = VoiceChatSession()
        if await session.connect():
            await session.send_text("Ø³Ù„Ø§Ù…ØŒ Ø­Ø§Ù„Øª Ú†Ø·ÙˆØ±Ù‡ØŸ")
            async for response in session.receive():
                print(response)
            await session.close()
    
    asyncio.run(test())
